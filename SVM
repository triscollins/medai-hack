# =========================================================
# 1. Import Libraries & Load Data
# =========================================================

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

# For our Deep Neural Network
import tensorflow as tf
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, Dropout

#For splitting the training and testing data
from sklearn.model_selection import train_test_split 

# Some display settings for nicer graphs
plt.rcParams['figure.figsize'] = (10, 6)
sns.set_style('whitegrid')

# Load dataset
dataset_df = pd.read_csv('/kaggle/input/medhack-ai-hospital-datasets/train_data.csv')
print("Data Loaded! Shape:", dataset_df.shape)
print(dataset_df.head())

# Load submission data
submission_df = pd.read_csv('/kaggle/input/medhack-ai-hospital-datasets/test_data.csv')
print("Submission Data Loaded! Shape:", submission_df.shape)
print(submission_df.head())


# 2.1: Drop columns we don't want or need from training data
# They might not directly help us predict in a simple DNN approach.
dataset_df = dataset_df.drop([
    'timestamp', 'patient_id', 'first_name', 'last_name', 
    'age', 'address', 'gender', 'city', 'state', 'postcode'
], axis=1)


submission_df = submission_df.drop([
    'timestamp', 'patient_id', 'first_name', 'last_name', 
    'age', 'address', 'gender', 'city', 'state', 'postcode'
], axis=1)



# =========================================================
# 2. Preprocessing
# =========================================================


# 2.1: Check for missing values
print("Missing values in training data:\n", dataset_df.isna().sum())

# Example strategy: just drop rows with missing data.
# (Real-world might do more nuanced imputation.)
dataset_df = dataset_df.dropna()
submission_df = submission_df.dropna()


# 2.2: Extract features (X) and labels (y) from the training set
X_all = dataset_df.drop('state_label', axis=1)
y_all = dataset_df['state_label']

# Convert labels {2,3} -> 1 to make it binary
#y_all = y_all.replace({2: 1, 3: 1})

# Perform the split (80% train, 20% test)
X_train, X_test, y_train, y_test = train_test_split(
    X_all, 
    y_all,
    test_size=0.2,     # Size of the test set (0.25 = 25% of data)
    random_state=42,     # Set seed for reproducibility
    shuffle=True         # Shuffle the data before splitting
)

#2.4 Print shape of training set
print("Training Features shape:", X_train.shape)
print("Training Labels shape:", y_train.shape)


#2.4 Print shape of testing set
print("Training Features shape:", X_test.shape)
print("Training Labels shape:", y_test.shape)


submission_df_predict = submission_df.drop(['ID'], axis=1)

from sklearn.preprocessing import StandardScaler

# Initialize the scaler
scaler = StandardScaler()

# Fit the scaler on X_train
scaler.fit(X_train)

# Transform both X_train and X_test
X_train_scaled = scaler.transform(X_train)
X_test_scaled = scaler.transform(X_test)
submission_scaled = scaler.transform(submission_df_predict)



# =========================================================
# 3. SVM
# =========================================================
from sklearn import svm

# Initialize the SVM classifier with 'balanced' class weights
clf = svm.SVC(class_weight='balanced', kernel='linear')

# Fit the model to the training data
clf.fit(X_train_scaled, y_train)

# Make predictions on new data
predictions = clf.predict(X_test_scaled)

# Print overall accuracy
print("SVM:", accuracy_score(y_test, predictions))



# =========================================================
# 4. SVM predictions on submission data
# =========================================================

# Make predictions on 
submission_predictions = clf.predict(submission_scaled)

# Create a DataFrame from the predicted labels
predictions = pd.DataFrame(submission_predictions, columns=['predicted_label'])

# Make prediction dataframe for submission
predictions_df = pd.DataFrame({
    'ID': submission_df['ID'],  # Keep the same ID from test data
    'predicted_label': predictions['predicted_label']
})

# Save DataFrame to csv
predictions_df.to_csv('predictions.csv', index=False)

from IPython.display import FileLink
FileLink(r'predictions.csv')




