# =========================================================
# 1. Import Libraries & Load Data
# =========================================================

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

# For our Deep Neural Network
import tensorflow as tf
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, Dropout

#For splitting the training and testing data
from sklearn.model_selection import train_test_split 

# Some display settings for nicer graphs
plt.rcParams['figure.figsize'] = (10, 6)
sns.set_style('whitegrid')

# Load dataset
dataset_df = pd.read_csv('/kaggle/input/medhack-ai-hospital-datasets/train_data.csv')
print("Data Loaded! Shape:", dataset_df.shape)
print(dataset_df.head())

# Load submission data
submission_df = pd.read_csv('/kaggle/input/medhack-ai-hospital-datasets/test_data.csv')
print("Submission Data Loaded! Shape:", submission_df.shape)
print(submission_df.head())


# 2.1: Drop columns we don't want or need from training data
# They might not directly help us predict in a simple DNN approach.
dataset_df = dataset_df.drop([
    'timestamp', 'patient_id', 'first_name', 'last_name', 
    'age', 'address', 'gender', 'city', 'state', 'postcode'
], axis=1)


submission_df = submission_df.drop([
    'timestamp', 'patient_id', 'first_name', 'last_name', 
    'age', 'address', 'gender', 'city', 'state', 'postcode'
], axis=1)



# =========================================================
# 2. Preprocessing
# =========================================================


# 2.1: Check for missing values
print("Missing values in training data:\n", dataset_df.isna().sum())

# Example strategy: just drop rows with missing data.
# (Real-world might do more nuanced imputation.)
dataset_df = dataset_df.dropna()
submission_df = submission_df.dropna()


# 2.2: Extract features (X) and labels (y) from the training set
X_all = dataset_df.drop('state_label', axis=1)
y_all = dataset_df['state_label']

# Convert labels {2,3} -> 1 to make it binary
#y_all = y_all.replace({2: 1, 3: 1})

# Perform the split (80% train, 20% test)
X_train, X_test, y_train, y_test = train_test_split(
    X_all, 
    y_all,
    test_size=0.2,     # Size of the test set (0.25 = 25% of data)
    random_state=42,     # Set seed for reproducibility
    shuffle=True         # Shuffle the data before splitting
)

#2.4 Print shape of training set
print("Training Features shape:", X_train.shape)
print("Training Labels shape:", y_train.shape)


#2.4 Print shape of testing set
print("Training Features shape:", X_test.shape)
print("Training Labels shape:", y_test.shape)

from sklearn.preprocessing import StandardScaler

submission_df_predict = submission_df.drop(['ID'], axis=1)

# Initialize the scaler
scaler = MinMaxScaler()

# Fit the scaler on X_train
scaler.fit(X_train)

# Transform both X_train and X_test
X_train_scaled = scaler.transform(X_train)
X_test_scaled = scaler.transform(X_test)
submission_scaled = scaler.transform(submission_df_predict)


# =========================================================
# 3. Ensemble with penalties
# =========================================================


from sklearn.ensemble import RandomForestClassifier, VotingClassifier
from sklearn.neighbors import KNeighborsClassifier
from sklearn.metrics import accuracy_score, make_scorer
from sklearn.utils.class_weight import compute_class_weight
import numpy as np
import pandas as pd
from IPython.display import FileLink

def weighted_accuracy_score(y_true, y_pred, class_penalties):
    """
    Custom scoring function that applies penalties for incorrect predictions
    based on class importance
    """
    correct = (y_true == y_pred)
    weights = np.array([class_penalties[label] for label in y_true])
    return np.sum(correct * weights) / np.sum(weights)

# Compute class weights based on frequency
unique_classes = np.unique(y_train)
class_weights = compute_class_weight(
    class_weight='balanced',
    classes=unique_classes,
    y=y_train
)

# Create penalty dictionary (higher penalty for underrepresented classes)
class_penalties = dict(zip(unique_classes, class_weights))

# Create custom scorer
weighted_scorer = make_scorer(
    weighted_accuracy_score,
    class_penalties=class_penalties
)

# Create base models
knn_model = KNeighborsClassifier(
    n_neighbors=5,
    weights='distance'  # Weight points by distance - this helps with class imbalance
)

rf_model = RandomForestClassifier(
    class_weight='balanced',  # For imbalanced dataset
    n_estimators=10,
    random_state=42
)

# Create voting classifier with adjusted weights for RF vs KNN
# Give slightly more weight to RF since it handles class imbalance better
ensemble = VotingClassifier(
    estimators=[
        ('knn', knn_model),
        ('rf', rf_model)
    ],
    weights=[0.4, 0.6],  # Give more weight to RF predictions
    voting='soft'  # Use probability predictions
)

# Fit the models separately
# KNN without sample weights
knn_model.fit(X_train_scaled, y_train)

# RF with sample weights
sample_weights = np.array([class_penalties[label] for label in y_train])
rf_model.fit(X_train_scaled, y_train, sample_weight=sample_weights)

# Fit the ensemble (this combines the already-fitted base models)
ensemble.fit(X_train_scaled, y_train)

# Make predictions on test set
ensemble_predictions = ensemble.predict(X_test_scaled)

# Print model performance metrics
print("Model Performance on Test Set:")
print("==============================")
print("Standard Accuracy:", accuracy_score(y_test, ensemble_predictions))
print("Weighted Accuracy:", weighted_accuracy_score(y_test, ensemble_predictions, class_penalties))

# Print class-specific performance
for class_label in unique_classes:
    mask = y_test == class_label
    class_acc = accuracy_score(y_test[mask], ensemble_predictions[mask])
    print(f"Class {class_label} Accuracy: {class_acc:.3f}")



# =========================================================
# 4. Predictions on submission data
# =========================================================


# Make predictions using the penalty-weighted ensemble
submission_predictions = ensemble.predict(submission_scaled)

# Create submission DataFrame
predictions_df = pd.DataFrame({
    'ID': submission_df['ID'],
    'predicted_label': submission_predictions
})

# Save predictions to CSV
output_file = 'predictions_weighted_ensemble.csv'
predictions_df.to_csv(output_file, index=False)

# Display download link
FileLink(output_file)
